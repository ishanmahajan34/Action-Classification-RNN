{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"},"colab":{"name":"RNN_ActionClassify.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"g9gL6InhzGno","colab_type":"text"},"source":["# Sequence Classification using Recurrent Neural Networks(RNN)\n","In this homework, you will learn how to train a recurrent neural network for human action classification. RNN is designed handle sequential data. The network can incorporate both past history and current input. [This](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) is a very good tutorial. You should read it before you start."]},{"cell_type":"markdown","metadata":{"id":"XFlewEI6zGnt","colab_type":"text"},"source":["## Setup\n","Please make sure you have h5py and torchnet installed\n","> pip install h5py\n","\n","> pip install git+https://github.com/pytorch/tnt.git@master\n"]},{"cell_type":"code","metadata":{"id":"GBfrHYwjXe8R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":785},"outputId":"3560db06-4614-4c06-8563-c13e51ee3fd6","executionInfo":{"status":"ok","timestamp":1576118680966,"user_tz":300,"elapsed":13703,"user":{"displayName":"Ishan Sachin Mahajan","photoUrl":"","userId":"00655263245018704430"}}},"source":["!pip install h5py\n","!pip install git+https://github.com/pytorch/tnt.git@master"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.8.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n","Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.17.4)\n","Collecting git+https://github.com/pytorch/tnt.git@master\n","  Cloning https://github.com/pytorch/tnt.git (to revision master) to /tmp/pip-req-build-eyjyrb9_\n","  Running command git clone -q https://github.com/pytorch/tnt.git /tmp/pip-req-build-eyjyrb9_\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchnet==0.0.5.1) (1.3.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchnet==0.0.5.1) (1.12.0)\n","Collecting visdom\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/75/e078f5a2e1df7e0d3044749089fc2823e62d029cc027ed8ae5d71fafcbdc/visdom-0.1.8.9.tar.gz (676kB)\n","\u001b[K     |████████████████████████████████| 686kB 8.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchnet==0.0.5.1) (1.17.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.5.1) (1.3.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.5.1) (2.21.0)\n","Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.5.1) (4.5.3)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.5.1) (17.0.0)\n","Collecting jsonpatch\n","  Downloading https://files.pythonhosted.org/packages/86/7e/035d19a73306278673039f0805b863be8798057cc1b4008b9c8c7d1d32a3/jsonpatch-1.24-py2.py3-none-any.whl\n","Collecting torchfile\n","  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n","Collecting websocket-client\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n","\u001b[K     |████████████████████████████████| 204kB 56.6MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.5.1) (4.3.0)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.5.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.5.1) (2019.11.28)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.5.1) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.5.1) (2.8)\n","Collecting jsonpointer>=1.9\n","  Downloading https://files.pythonhosted.org/packages/18/b0/a80d29577c08eea401659254dfaed87f1af45272899e1812d7e01b679bc5/jsonpointer-2.0-py2.py3-none-any.whl\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->visdom->torchnet==0.0.5.1) (0.46)\n","Building wheels for collected packages: torchnet, visdom, torchfile\n","  Building wheel for torchnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchnet: filename=torchnet-0.0.5.1-cp36-none-any.whl size=30917 sha256=97460ad706063b05d335ae7c6bc0ff9cfeef27c61abb0cdf8a04a85f100f9896\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-q8ru0zhq/wheels/17/05/ec/d05d051a225871af52bf504f5e8daf57704811b3c1850d0012\n","  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for visdom: filename=visdom-0.1.8.9-cp36-none-any.whl size=655252 sha256=c33dfa69e7174f7d064ded40ad700243bd91ccbe2d430f17332868ed8a97690a\n","  Stored in directory: /root/.cache/pip/wheels/70/19/a7/6d589ed967f4dfefd33bc166d081257bd4ed0cb618dccfd62a\n","  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchfile: filename=torchfile-0.1.0-cp36-none-any.whl size=5711 sha256=196164879e551c6ea9fc93f6124b3d05b70ab68dc713265b1e3596349ddb5962\n","  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n","Successfully built torchnet visdom torchfile\n","Installing collected packages: jsonpointer, jsonpatch, torchfile, websocket-client, visdom, torchnet\n","Successfully installed jsonpatch-1.24 jsonpointer-2.0 torchfile-0.1.0 torchnet-0.0.5.1 visdom-0.1.8.9 websocket-client-0.56.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xzmKOyGAzGnw","colab_type":"code","outputId":"f0746e7a-36b1-4e9c-ca19-bbb059674287","executionInfo":{"status":"ok","timestamp":1576118692949,"user_tz":300,"elapsed":867,"user":{"displayName":"Ishan Sachin Mahajan","photoUrl":"","userId":"00655263245018704430"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","import numpy as np\n","import h5py\n","\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torch.utils.data as DD\n","import torchnet as tnt\n","\n","use_cuda = torch.cuda.is_available()\n","print('use cuda: %s'%(use_cuda))\n","FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n","LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n","ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor"],"execution_count":2,"outputs":[{"output_type":"stream","text":["use cuda: True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2usLYKYgXsCk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"32a522d2-e588-44e2-e78e-118727873aab","executionInfo":{"status":"ok","timestamp":1576118727569,"user_tz":300,"elapsed":33499,"user":{"displayName":"Ishan Sachin Mahajan","photoUrl":"","userId":"00655263245018704430"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yvSE-_f1X7Fw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"695d3a51-6286-44c3-e484-693083d7f798","executionInfo":{"status":"ok","timestamp":1576118732346,"user_tz":300,"elapsed":896,"user":{"displayName":"Ishan Sachin Mahajan","photoUrl":"","userId":"00655263245018704430"}}},"source":["cd '/content/drive/My Drive/hw6(1)/Question3'"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/hw6(1)/Question3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gMuQMMsCzGn_","colab_type":"text"},"source":["## Dataset\n","The data we are using is skeleton data, which indicates the 3D locations of body joints. In total, there are 25 body joints. It is collected by Kinect v2. To make it easier, each sequence have same number of frames. You need to classify 10 different actions. There are 2000 training sequences, 400 validation sequences, and 500 test sequences. Each sequence has 15 frames, each frame is a 75-dimension vector (3*25). \n","\n","For your convenience, we provide the dataloader for you.\n"]},{"cell_type":"code","metadata":{"id":"EXO8pvo2zGoC","colab_type":"code","colab":{}},"source":["class Dataset(DD.Dataset):\n","    # subset can be: 'train', 'val', 'test'\n","    def __init__(self, data_path, subset='train'):\n","        super(Dataset, self).__init__()\n","        self.data_path = os.path.join(data_path, '%s_data.h5'%subset)\n","        self.subset = subset\n","\n","        with h5py.File(self.data_path) as f:\n","            self.data = np.array(f['data'])\n","\n","        if subset != 'test':\n","            self.label_path = os.path.join(data_path, '%s_label.h5'%subset)\n","            with h5py.File(self.label_path) as f:\n","                self.label = np.array(f['label'])\n","\n","        self.num_sequences = self.data.shape[0]\n","        self.seq_len = self.data.shape[1]\n","        self.n_dim = self.data.shape[2]\n","\n","    def __getitem__(self, index):\n","        seq = self.data[index]\n","        if self.subset != 'test':\n","            label = int(self.label[index])\n","            sample = {'seq': seq, 'label': label}\n","        else:\n","            sample = {'seq': seq}\n","        return sample\n","\n","    def __len__(self):\n","        return self.num_sequences\n","\n","trSet = Dataset('./data', subset='train')\n","valSet = Dataset('./data', subset='val')\n","tstSet = Dataset('./data', subset='test')\n","\n","batch_size = 50\n","trLD = DD.DataLoader(trSet, batch_size=batch_size,\n","       sampler=DD.sampler.RandomSampler(trSet),\n","       num_workers=2, pin_memory=False)\n","valLD = DD.DataLoader(valSet, batch_size=batch_size,\n","       sampler=DD.sampler.SequentialSampler(valSet),\n","       num_workers=1, pin_memory=False)\n","tstLD = DD.DataLoader(tstSet, batch_size=batch_size,\n","       sampler=DD.sampler.SequentialSampler(tstSet),\n","       num_workers=1, pin_memory=False)\n","\n","input_dim = trSet.n_dim\n","num_class = 10"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WYZs2LMkzGoJ","colab_type":"text"},"source":["## Model\n","Pytorch has implemented different types of recurrent layers for you. For this homework, you can use any type of RNNs as you want:\n","> torch.nn.RNN()\n","\n","> torch.nn.LSTM()\n","\n","> torch.nn.GRU()\n","\n","You can check details for different types of recurrent layers here: [RNN](http://pytorch.org/docs/master/nn.html#torch.nn.RNN), [LSTM]( http://pytorch.org/docs/master/nn.html#torch.nn.LSTM), [GRU](http://pytorch.org/docs/master/nn.html#torch.nn.GRU)\n","\n","\n","### Implement a specific model\n","In this section, you need to implement a model for sequence classification. The model has following layers:\n","* A linear layer that can map features of 75-dimension to 100-dimension.\n","* 1 Layer LSTM layer with hidden size of 100\n","* A linear layer that goes from 100 to num_class (10). \n","\n","An LSTM layer takes an input of size of (batch_size, seq_len, fea_dim) and outputs a variable of shape (batch_size, seq_len, hidden_size). In this homework, the classification score for a sequence is the classification score for the last step of rnn_outputs.\n","\n"]},{"cell_type":"code","metadata":{"id":"p7fj2fjTzGoL","colab_type":"code","colab":{}},"source":["# sequence classification model\n","class SequenceClassify(nn.Module):\n","    def __init__(self):\n","        super(SequenceClassify, self).__init__()\n","        \n","        ############## 1st To Do (10 points) ##############\n","        ###################################################\n","        self.project_layer = nn.Linear(75, 100)\n","        self.recurrent_layer = nn.LSTM(100, 100)\n","        self.classify_layer = nn.Linear(100, 10)\n","        ###################################################\n","    \n","    # the size of input is [batch_size, seq_len(15), input_dim(75)]\n","    # the size of logits is [batch_size, num_class]\n","    def forward(self, input, h_t_1=None, c_t_1=None):\n","        # the size of rnn_outputs is [batch_size, seq_len, rnn_size]\n","        rnn_outputs, (hn, cn) = self.recurrent_layer(self.project_layer(input))\n","        # classify the last step of rnn_outpus\n","        # the size of logits is [batch_size, num_class]\n","        logits = self.classify_layer(rnn_outputs[:,-1])\n","        return logits\n","\n","model = SequenceClassify().cuda()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rQXf8dINzGoT","colab_type":"text"},"source":["## Train the model\n","After you have the dataloader and model, you can start training the model. Define a SGD optimizer with learning rate of 1e-3, and a cross-entropy loss function:"]},{"cell_type":"code","metadata":{"id":"zo8WUdiIzGoU","colab_type":"code","colab":{}},"source":["################ 2nd To Do  (5 points)##################\n","optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3)\n","criterion = torch.nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nbus_qJIzGoZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"240bd4ef-f992-4626-a1da-cf138cbe4a38","executionInfo":{"status":"ok","timestamp":1576118766775,"user_tz":300,"elapsed":1186,"user":{"displayName":"Ishan Sachin Mahajan","photoUrl":"","userId":"00655263245018704430"}}},"source":["# run the model for one epoch\n","# can be used for both training or validation model\n","def run_epoch(data_loader, model, criterion, epoch, is_training, optimizer=None):\n","    if is_training:\n","        model.train()\n","        logger_prefix = 'train'\n","    else:\n","        model.eval()\n","        logger_prefix = 'val'\n","\n","    confusion_matrix = tnt.meter.ConfusionMeter(num_class)\n","    acc = tnt.meter.ClassErrorMeter(accuracy=True)\n","    meter_loss = tnt.meter.AverageValueMeter()\n","\n","    for batch_idx, sample in enumerate(data_loader):\n","        sequence = sample['seq']\n","        label = sample['label']\n","        input_sequence_var = Variable(sequence).type(FloatTensor)\n","        input_label_var = Variable(label).type(LongTensor)\n","\n","        # compute output\n","        # output_logits: [batch_size, num_class]\n","        output_logits = model(input_sequence_var)\n","        loss = criterion(output_logits, input_label_var)\n","\n","        if is_training:\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        meter_loss.add(loss.item())\n","        acc.add(output_logits.data, input_label_var.data)\n","        confusion_matrix.add(output_logits.data, input_label_var.data)\n","\n","\n","    print('%s Epoch: %d  , Loss: %.4f,  Accuracy: %.2f'%(logger_prefix, epoch, meter_loss.value()[0], acc.value()[0]))\n","    return acc.value()[0]\n","\n","num_epochs = 1\n","evaluate_every_epoch = 5\n","for e in range(num_epochs):\n","    run_epoch(trLD, model, criterion, e, True, optimizer)\n","    if e % evaluate_every_epoch == 0:\n","        run_epoch(valLD, model, criterion, e, False, None)   \n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["train Epoch: 0  , Loss: 2.3212,  Accuracy: 10.00\n","val Epoch: 0  , Loss: 2.3232,  Accuracy: 10.75\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"r_hqe-krzGod","colab_type":"text"},"source":["## Submit your results \n","\n","### Train a better model for action recognition!\n","Now it's your job to experiment with architectures, hyperparameters, loss functions, and optimizers to train a model that achieves better accuracy on the action recognition validation set. \n","\n","\n","### Testing the model and reporting the results\n","Test the model on the testing set and save the results as a .csv file. \n","submit the results.csv file generated by predict_on_test(). Also mention the best performance on the Validation set, and submit the corresponding results csv file which results in the best performance. \n","################ 3rd To Do  (15 points) ###############\n"]},{"cell_type":"code","metadata":{"id":"qGHWoygkfBwc","colab_type":"code","colab":{}},"source":["class Flatten(nn.Module):\n","    def forward(self, x):\n","        N, C, H, W = x.size()\n","        return x.view(N, -1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KaONG74BeaeU","colab_type":"code","colab":{}},"source":["class ActionClassifyNet(nn.Module):\n","    def __init__(self):\n","        super(ActionClassifyNet, self).__init__()\n","        self.conv_layer = nn.Sequential( \n","            nn.Conv2d(1, 200, kernel_size=(3, 3)),\n","            nn.MaxPool2d(2, 2),\n","            nn.LeakyReLU(0.04),\n","            nn.BatchNorm2d(200),\n","            nn.Conv2d(200, 100, 2, 1),\n","            nn.MaxPool2d(2, 2),\n","            nn.LeakyReLU(0.04),\n","            nn.BatchNorm2d(100),\n","            Flatten(),\n","            nn.Linear(3400, 100)\n","        )\n","        \n","        self.recurrent_layer = nn.LSTM(100, 100, 1)\n","        self.classify_layer = nn.Linear(100, 10)\n","        \n","        \n","    def forward(self, input, h_t_1=None, c_t_1=None):\n","        rnn_outputs = self.conv_layer(input.view(50, 1, 15, 75))\n","        rnn_outputs, (hn, cn) = self.recurrent_layer(rnn_outputs.view(50, 1, 100))        \n","        logits = self.classify_layer(rnn_outputs[:,-1])\n","        \n","        return logits\n","\n","model = ActionClassifyNet().cuda()\n","optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4)\n","criterion = nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o4E9Az8pAHr8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"e5817171-9721-482b-8041-c62811b0f38c","executionInfo":{"status":"ok","timestamp":1576118842038,"user_tz":300,"elapsed":25280,"user":{"displayName":"Ishan Sachin Mahajan","photoUrl":"","userId":"00655263245018704430"}}},"source":["num_epoches = 50\n","for i in range(num_epoches):\n","  print(\"EPOCH \", i)\n","  run_epoch(trLD, model, criterion, e, True, optimizer)\n","  run_epoch(valLD, model, criterion, e, False, None)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["EPOCH  0\n","train Epoch: 0  , Loss: 2.2512,  Accuracy: 17.35\n","val Epoch: 0  , Loss: 2.1973,  Accuracy: 24.25\n","EPOCH  1\n","train Epoch: 0  , Loss: 2.0238,  Accuracy: 37.20\n","val Epoch: 0  , Loss: 1.8445,  Accuracy: 54.25\n","EPOCH  2\n","train Epoch: 0  , Loss: 1.6586,  Accuracy: 59.05\n","val Epoch: 0  , Loss: 1.4382,  Accuracy: 66.50\n","EPOCH  3\n","train Epoch: 0  , Loss: 1.3428,  Accuracy: 65.95\n","val Epoch: 0  , Loss: 1.1967,  Accuracy: 69.00\n","EPOCH  4\n","train Epoch: 0  , Loss: 1.1383,  Accuracy: 70.45\n","val Epoch: 0  , Loss: 1.0585,  Accuracy: 74.75\n","EPOCH  5\n","train Epoch: 0  , Loss: 1.0286,  Accuracy: 72.20\n","val Epoch: 0  , Loss: 0.9616,  Accuracy: 74.00\n","EPOCH  6\n","train Epoch: 0  , Loss: 0.9394,  Accuracy: 73.60\n","val Epoch: 0  , Loss: 0.9439,  Accuracy: 75.25\n","EPOCH  7\n","train Epoch: 0  , Loss: 0.8786,  Accuracy: 75.95\n","val Epoch: 0  , Loss: 0.8451,  Accuracy: 77.75\n","EPOCH  8\n","train Epoch: 0  , Loss: 0.8316,  Accuracy: 76.40\n","val Epoch: 0  , Loss: 0.8163,  Accuracy: 78.50\n","EPOCH  9\n","train Epoch: 0  , Loss: 0.7774,  Accuracy: 78.45\n","val Epoch: 0  , Loss: 0.7583,  Accuracy: 79.25\n","EPOCH  10\n","train Epoch: 0  , Loss: 0.7442,  Accuracy: 79.35\n","val Epoch: 0  , Loss: 0.7447,  Accuracy: 78.00\n","EPOCH  11\n","train Epoch: 0  , Loss: 0.7024,  Accuracy: 80.60\n","val Epoch: 0  , Loss: 0.7035,  Accuracy: 80.75\n","EPOCH  12\n","train Epoch: 0  , Loss: 0.6628,  Accuracy: 81.95\n","val Epoch: 0  , Loss: 0.6807,  Accuracy: 81.00\n","EPOCH  13\n","train Epoch: 0  , Loss: 0.6291,  Accuracy: 83.30\n","val Epoch: 0  , Loss: 0.6535,  Accuracy: 80.00\n","EPOCH  14\n","train Epoch: 0  , Loss: 0.6045,  Accuracy: 83.80\n","val Epoch: 0  , Loss: 0.6344,  Accuracy: 81.25\n","EPOCH  15\n","train Epoch: 0  , Loss: 0.5781,  Accuracy: 85.10\n","val Epoch: 0  , Loss: 0.6427,  Accuracy: 79.50\n","EPOCH  16\n","train Epoch: 0  , Loss: 0.5491,  Accuracy: 86.15\n","val Epoch: 0  , Loss: 0.6101,  Accuracy: 81.50\n","EPOCH  17\n","train Epoch: 0  , Loss: 0.5170,  Accuracy: 86.30\n","val Epoch: 0  , Loss: 0.6044,  Accuracy: 81.25\n","EPOCH  18\n","train Epoch: 0  , Loss: 0.4965,  Accuracy: 87.40\n","val Epoch: 0  , Loss: 0.5754,  Accuracy: 82.75\n","EPOCH  19\n","train Epoch: 0  , Loss: 0.4768,  Accuracy: 87.65\n","val Epoch: 0  , Loss: 0.5981,  Accuracy: 81.25\n","EPOCH  20\n","train Epoch: 0  , Loss: 0.4525,  Accuracy: 88.65\n","val Epoch: 0  , Loss: 0.5684,  Accuracy: 82.25\n","EPOCH  21\n","train Epoch: 0  , Loss: 0.4359,  Accuracy: 88.85\n","val Epoch: 0  , Loss: 0.5442,  Accuracy: 82.50\n","EPOCH  22\n","train Epoch: 0  , Loss: 0.4202,  Accuracy: 89.45\n","val Epoch: 0  , Loss: 0.5320,  Accuracy: 82.25\n","EPOCH  23\n","train Epoch: 0  , Loss: 0.3973,  Accuracy: 90.05\n","val Epoch: 0  , Loss: 0.5214,  Accuracy: 83.00\n","EPOCH  24\n","train Epoch: 0  , Loss: 0.3766,  Accuracy: 90.90\n","val Epoch: 0  , Loss: 0.5550,  Accuracy: 83.25\n","EPOCH  25\n","train Epoch: 0  , Loss: 0.3629,  Accuracy: 90.85\n","val Epoch: 0  , Loss: 0.5232,  Accuracy: 83.50\n","EPOCH  26\n","train Epoch: 0  , Loss: 0.3415,  Accuracy: 92.00\n","val Epoch: 0  , Loss: 0.5058,  Accuracy: 83.50\n","EPOCH  27\n","train Epoch: 0  , Loss: 0.3248,  Accuracy: 92.50\n","val Epoch: 0  , Loss: 0.4952,  Accuracy: 84.00\n","EPOCH  28\n","train Epoch: 0  , Loss: 0.3131,  Accuracy: 93.20\n","val Epoch: 0  , Loss: 0.5148,  Accuracy: 82.75\n","EPOCH  29\n","train Epoch: 0  , Loss: 0.3095,  Accuracy: 92.55\n","val Epoch: 0  , Loss: 0.4929,  Accuracy: 84.00\n","EPOCH  30\n","train Epoch: 0  , Loss: 0.2949,  Accuracy: 93.75\n","val Epoch: 0  , Loss: 0.4806,  Accuracy: 85.00\n","EPOCH  31\n","train Epoch: 0  , Loss: 0.2786,  Accuracy: 93.95\n","val Epoch: 0  , Loss: 0.4629,  Accuracy: 83.75\n","EPOCH  32\n","train Epoch: 0  , Loss: 0.2637,  Accuracy: 94.20\n","val Epoch: 0  , Loss: 0.4615,  Accuracy: 83.00\n","EPOCH  33\n","train Epoch: 0  , Loss: 0.2491,  Accuracy: 95.15\n","val Epoch: 0  , Loss: 0.4451,  Accuracy: 84.25\n","EPOCH  34\n","train Epoch: 0  , Loss: 0.2414,  Accuracy: 94.50\n","val Epoch: 0  , Loss: 0.4614,  Accuracy: 84.25\n","EPOCH  35\n","train Epoch: 0  , Loss: 0.2308,  Accuracy: 96.05\n","val Epoch: 0  , Loss: 0.4477,  Accuracy: 85.50\n","EPOCH  36\n","train Epoch: 0  , Loss: 0.2195,  Accuracy: 95.70\n","val Epoch: 0  , Loss: 0.4522,  Accuracy: 83.25\n","EPOCH  37\n","train Epoch: 0  , Loss: 0.2059,  Accuracy: 96.35\n","val Epoch: 0  , Loss: 0.4445,  Accuracy: 85.00\n","EPOCH  38\n","train Epoch: 0  , Loss: 0.1962,  Accuracy: 96.30\n","val Epoch: 0  , Loss: 0.4338,  Accuracy: 83.50\n","EPOCH  39\n","train Epoch: 0  , Loss: 0.1868,  Accuracy: 96.60\n","val Epoch: 0  , Loss: 0.4703,  Accuracy: 82.75\n","EPOCH  40\n","train Epoch: 0  , Loss: 0.1787,  Accuracy: 96.90\n","val Epoch: 0  , Loss: 0.4587,  Accuracy: 84.25\n","EPOCH  41\n","train Epoch: 0  , Loss: 0.1820,  Accuracy: 96.10\n","val Epoch: 0  , Loss: 0.4490,  Accuracy: 84.00\n","EPOCH  42\n","train Epoch: 0  , Loss: 0.1692,  Accuracy: 97.20\n","val Epoch: 0  , Loss: 0.4120,  Accuracy: 85.50\n","EPOCH  43\n","train Epoch: 0  , Loss: 0.1559,  Accuracy: 97.25\n","val Epoch: 0  , Loss: 0.4175,  Accuracy: 85.00\n","EPOCH  44\n","train Epoch: 0  , Loss: 0.1461,  Accuracy: 97.85\n","val Epoch: 0  , Loss: 0.4316,  Accuracy: 84.00\n","EPOCH  45\n","train Epoch: 0  , Loss: 0.1335,  Accuracy: 97.95\n","val Epoch: 0  , Loss: 0.4403,  Accuracy: 84.75\n","EPOCH  46\n","train Epoch: 0  , Loss: 0.1338,  Accuracy: 98.05\n","val Epoch: 0  , Loss: 0.3860,  Accuracy: 86.25\n","EPOCH  47\n","train Epoch: 0  , Loss: 0.1292,  Accuracy: 98.30\n","val Epoch: 0  , Loss: 0.4139,  Accuracy: 84.00\n","EPOCH  48\n","train Epoch: 0  , Loss: 0.1223,  Accuracy: 98.30\n","val Epoch: 0  , Loss: 0.4246,  Accuracy: 84.25\n","EPOCH  49\n","train Epoch: 0  , Loss: 0.1122,  Accuracy: 98.70\n","val Epoch: 0  , Loss: 0.4287,  Accuracy: 84.50\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rzwpNlHVAXyc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"798a76ad-4318-4b6c-9dda-8d2ab03e340c","executionInfo":{"status":"ok","timestamp":1576118915151,"user_tz":300,"elapsed":999,"user":{"displayName":"Ishan Sachin Mahajan","photoUrl":"","userId":"00655263245018704430"}}},"source":["# Use your best model to generate results on test set and validation set.\n","# generate csv file for test set\n","def predict_on_test(model, data_loader):\n","    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n","    results=open('results_val.csv','w')\n","    count=0\n","    results.write('Id'+','+'Class'+'\\n')\n","    for batch_idx, sample in enumerate(data_loader):\n","        sequence = sample['seq']\n","        input_sequence_var = Variable(sequence).type(FloatTensor)\n","        scores = model(input_sequence_var)\n","        _, preds = scores.data.max(1)\n","        for i in range(len(preds)):\n","            results.write(str(count)+','+str(preds[i])+'\\n')\n","            count+=1\n","    results.close()\n","    return count\n","\n","count=predict_on_test(model, valLD)\n","print(count)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["400\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n87MwbsGzGoe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ac823cfa-f6c0-4438-a3bb-4a2e7e5b48ad","executionInfo":{"status":"ok","timestamp":1576118924552,"user_tz":300,"elapsed":1291,"user":{"displayName":"Ishan Sachin Mahajan","photoUrl":"","userId":"00655263245018704430"}}},"source":["# Use your best model to generate results on test set and validation set.\n","# generate csv file for test set\n","def predict_on_test(model, data_loader):\n","    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n","    results=open('results.csv','w')\n","    count=0\n","    results.write('Id'+','+'Class'+'\\n')\n","    for batch_idx, sample in enumerate(data_loader):\n","        sequence = sample['seq']\n","        input_sequence_var = Variable(sequence).type(FloatTensor)\n","        scores = model(input_sequence_var)\n","        _, preds = scores.data.max(1)\n","        for i in range(len(preds)):\n","            results.write(str(count)+','+str(preds[i])+'\\n')\n","            count+=1\n","    results.close()\n","    return count\n","\n","count=predict_on_test(model, tstLD)\n","print(count)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["500\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yJua9UOMzGoi","colab_type":"text"},"source":["## Report the performance\n","################ 4th To Do  (5 points)##################\n","\n","In this cell, you should write an explanation of what you did (network architecture, optimiziter, learning rate, epoches) and any visualizations or graphs that you make in the process of training and evaluating your network.\n","\n","Network Architecture\n","\n","*\t3 X 3 convolution layer with 200 filters and default stride 1.\n","*\tMax Pool layer with size 2X2.\n","*\tLeaky ReLU.\n","*   Batch Normalization\n","*\tConvolution layer with 100 filters and default stride 1.\n","*\tMax Pool layer with size 2X2.\n","*\tLeaky ReLU.\n","*   Batch Normalization\n","*\tFlatten.\n","*   Batch Normalization\n","*\tLinear Layer to reduce inputs from 3400 to 100.\n","*   LSTM layer\n","*\tLinear Layer to reduce inputs from 100 to 10.\n","\n","*\tOptimizer is Adam\n","*\tTotal Epochs = 50\n","*\tlearning rate = 1e-4\n","\n","\n","Final Training accuracy = 98.70%\n","\n","Final Validation accuracy = 84.50%"]},{"cell_type":"code","metadata":{"id":"S2GuwYiKFFJW","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}